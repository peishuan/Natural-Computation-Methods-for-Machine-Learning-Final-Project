{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[171.005]\n",
      " [144.026]\n",
      " [116.971]\n",
      " [121.975]\n",
      " [110.962]\n",
      " [112.022]\n",
      " [128.977]\n",
      " [ 96.172]\n",
      " [116.735]\n",
      " [120.042]\n",
      " [101.085]\n",
      " [129.979]]\n"
     ]
    }
   ],
   "source": [
    "# Loading in trining data\n",
    "training_data = pd.read_csv(\"songinput.csv\")\n",
    "target_output = [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "training_data = training_data.drop(['no'], axis=1)\n",
    "\n",
    "# Delete non-number columns\n",
    "training_data = training_data.drop(['artist_name'], axis=1)\n",
    "training_data = training_data.drop(['track_name'], axis=1)\n",
    "training_data = training_data.drop(['track_id'], axis=1)\n",
    "training_data = training_data.drop(['uri'], axis=1)\n",
    "training_data = training_data.drop(['track_href'], axis=1)\n",
    "training_data = training_data.drop(['analysis_url'], axis=1)\n",
    "training_data = training_data.drop(['type'], axis=1)\n",
    "\n",
    "training_data = training_data.drop(['popularity'], axis=1)\n",
    "training_data = training_data.drop(['danceability'], axis=1)\n",
    "training_data = training_data.drop(['energy'], axis=1)\n",
    "training_data = training_data.drop(['key'], axis=1)\n",
    "training_data = training_data.drop(['loudness'], axis=1)\n",
    "training_data = training_data.drop(['mode'], axis=1)\n",
    "training_data = training_data.drop(['speechiness'], axis=1)\n",
    "training_data = training_data.drop(['acousticness'], axis=1)\n",
    "training_data = training_data.drop(['instrumentalness'], axis=1)\n",
    "training_data = training_data.drop(['liveness'], axis=1)\n",
    "training_data = training_data.drop(['valence'], axis=1)\n",
    "training_data = training_data.drop(['duration_ms'], axis=1)\n",
    "training_data = training_data.drop(['time_signature'], axis=1)\n",
    "\n",
    "training_data = np.asarray(training_data,dtype=np.float64)\n",
    "training_count = len(training_data[:,0])\n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[168.983]\n",
      " [ 91.019]]\n"
     ]
    }
   ],
   "source": [
    "# Loading in validation data\n",
    "validation_data = pd.read_csv(\"songinput2.csv\")\n",
    "validation_output = validation_data.no\n",
    "validation_data = validation_data.drop(['no'], axis=1)\n",
    "\n",
    "# Delete non-number columns\n",
    "validation_data = validation_data.drop(['artist_name'], axis=1)\n",
    "validation_data = validation_data.drop(['track_name'], axis=1)\n",
    "validation_data = validation_data.drop(['track_id'], axis=1)\n",
    "validation_data = validation_data.drop(['uri'], axis=1)\n",
    "validation_data = validation_data.drop(['track_href'], axis=1)\n",
    "validation_data = validation_data.drop(['analysis_url'], axis=1)\n",
    "validation_data = validation_data.drop(['type'], axis=1)\n",
    "\n",
    "validation_data = validation_data.drop(['popularity'], axis=1)\n",
    "validation_data = validation_data.drop(['danceability'], axis=1)\n",
    "validation_data = validation_data.drop(['energy'], axis=1)\n",
    "validation_data = validation_data.drop(['key'], axis=1)\n",
    "validation_data = validation_data.drop(['loudness'], axis=1)\n",
    "validation_data = validation_data.drop(['mode'], axis=1)\n",
    "validation_data = validation_data.drop(['speechiness'], axis=1)\n",
    "validation_data = validation_data.drop(['acousticness'], axis=1)\n",
    "validation_data = validation_data.drop(['instrumentalness'], axis=1)\n",
    "validation_data = validation_data.drop(['liveness'], axis=1)\n",
    "validation_data = validation_data.drop(['valence'], axis=1)\n",
    "validation_data = validation_data.drop(['duration_ms'], axis=1)\n",
    "validation_data = validation_data.drop(['time_signature'], axis=1)\n",
    "validation_data = np.asarray(validation_data,dtype=np.float64)\n",
    "validation_count = len(validation_data[:,0])\n",
    "print(validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin_peihsuan/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#class sklearn.neural_network.MLPClassifier(hidden_layer_sizes=(100, ), \n",
    "# activation='relu', solver='adam', alpha=0.0001, batch_size='auto', \n",
    "# learning_rate='constant', learning_rate_init=0.001, power_t=0.5, max_iter=200, \n",
    "# shuffle=True, random_state=None, tol=0.0001, verbose=False, warm_start=False, \n",
    "# momentum=0.9, nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, \n",
    "# beta_1=0.9, beta_2=0.999, epsilon=1e-08, n_iter_no_change=10, max_fun=15000)\n",
    "\n",
    "mlp = MLPClassifier(solver='lbfgs', activation='logistic',max_iter=1000)\n",
    "mlp.fit(training_data,target_output)\n",
    "\n",
    "mlp.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6 12  8  3  4 11 12]\n"
     ]
    }
   ],
   "source": [
    "y_pred = mlp.predict(training_data)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.75\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set score: {}\".format(mlp.score(training_data,target_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set score: 0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing set score: {}\".format(mlp.score(validation_data,validation_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set predicted ranking: [1 8]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set predicted ranking: {}\".format(mlp.predict(validation_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set score: [[8.79999875e-001 1.19952655e-001 1.76161865e-017 8.54705836e-011\n",
      "  9.14368595e-029 9.79549099e-026 7.76709553e-006 1.87518901e-068\n",
      "  6.67472438e-018 2.29792092e-013 1.90589603e-050 3.97021093e-005]\n",
      " [8.79875122e-124 3.30546748e-070 2.01921213e-017 9.15145849e-027\n",
      "  2.52923589e-008 2.36971782e-010 7.42553112e-040 9.95077938e-001\n",
      "  5.35742773e-017 5.02809379e-023 4.92203650e-003 4.17950223e-042]]\n"
     ]
    }
   ],
   "source": [
    "#probability to each label\n",
    "print(\"Testing set score: {}\".format(mlp.predict_proba(validation_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6\n",
      "1    8\n",
      "Name: no, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(validation_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00         0\n",
      "           6       0.00      0.00      0.00         1\n",
      "           8       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.33      0.33      0.33         2\n",
      "weighted avg       0.50      0.50      0.50         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lin_peihsuan/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/lin_peihsuan/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(validation_output,mlp.predict(validation_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(validation_output,mlp.predict(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
