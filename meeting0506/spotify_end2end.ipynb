{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.special import expit\n",
    "\n",
    "def logistic(x):\n",
    "    return 1.0/(1 + expit(-x))\n",
    "\n",
    "def logistic_deriv(x):\n",
    "    return logistic(x) * (1 - logistic(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1   \n",
    "\n",
    "I_dim = 1\n",
    "H_dim = 5\n",
    "\n",
    "epoch_count = 1\n",
    "\n",
    "np.random.seed(1)\n",
    "weights_ItoH = np.random.uniform(-1, 1, (I_dim, H_dim))\n",
    "weights_HtoO = np.random.uniform(-1, 1, H_dim)\n",
    "\n",
    "preActivation_H = np.zeros(H_dim)\n",
    "postActivation_H = np.zeros(H_dim)\n",
    "postActivation_O = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      1\n",
      "1      4\n",
      "2      8\n",
      "3      3\n",
      "4      9\n",
      "5     21\n",
      "6     14\n",
      "7     27\n",
      "8     28\n",
      "9     29\n",
      "10    31\n",
      "11     2\n",
      "Name: no, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Loading in trining data\n",
    "training_data = pd.read_csv(\"songinput.csv\")\n",
    "target_output = training_data.no\n",
    "training_data = training_data.drop(['no'], axis=1)\n",
    "\n",
    "# Delete non-number columns\n",
    "training_data = training_data.drop(['artist_name'], axis=1)\n",
    "training_data = training_data.drop(['track_name'], axis=1)\n",
    "training_data = training_data.drop(['track_id'], axis=1)\n",
    "training_data = training_data.drop(['uri'], axis=1)\n",
    "training_data = training_data.drop(['track_href'], axis=1)\n",
    "training_data = training_data.drop(['analysis_url'], axis=1)\n",
    "training_data = training_data.drop(['type'], axis=1)\n",
    "\n",
    "training_data = training_data.drop(['popularity'], axis=1)\n",
    "training_data = training_data.drop(['danceability'], axis=1)\n",
    "training_data = training_data.drop(['energy'], axis=1)\n",
    "training_data = training_data.drop(['key'], axis=1)\n",
    "training_data = training_data.drop(['loudness'], axis=1)\n",
    "training_data = training_data.drop(['mode'], axis=1)\n",
    "training_data = training_data.drop(['speechiness'], axis=1)\n",
    "training_data = training_data.drop(['acousticness'], axis=1)\n",
    "training_data = training_data.drop(['instrumentalness'], axis=1)\n",
    "training_data = training_data.drop(['liveness'], axis=1)\n",
    "training_data = training_data.drop(['valence'], axis=1)\n",
    "training_data = training_data.drop(['duration_ms'], axis=1)\n",
    "training_data = training_data.drop(['time_signature'], axis=1)\n",
    "\n",
    "training_data = np.asarray(training_data,dtype=np.float64)\n",
    "training_count = len(training_data[:,0])\n",
    "\n",
    "print(target_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    39\n",
      "1    45\n",
      "Name: no, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Loading in validation data\n",
    "validation_data = pd.read_csv(\"songinput2.csv\")\n",
    "validation_output = validation_data.no\n",
    "validation_data = validation_data.drop(['no'], axis=1)\n",
    "\n",
    "# Delete non-number columns\n",
    "validation_data = validation_data.drop(['artist_name'], axis=1)\n",
    "validation_data = validation_data.drop(['track_name'], axis=1)\n",
    "validation_data = validation_data.drop(['track_id'], axis=1)\n",
    "validation_data = validation_data.drop(['uri'], axis=1)\n",
    "validation_data = validation_data.drop(['track_href'], axis=1)\n",
    "validation_data = validation_data.drop(['analysis_url'], axis=1)\n",
    "validation_data = validation_data.drop(['type'], axis=1)\n",
    "\n",
    "validation_data = validation_data.drop(['popularity'], axis=1)\n",
    "validation_data = validation_data.drop(['danceability'], axis=1)\n",
    "validation_data = validation_data.drop(['energy'], axis=1)\n",
    "validation_data = validation_data.drop(['key'], axis=1)\n",
    "validation_data = validation_data.drop(['loudness'], axis=1)\n",
    "validation_data = validation_data.drop(['mode'], axis=1)\n",
    "validation_data = validation_data.drop(['speechiness'], axis=1)\n",
    "validation_data = validation_data.drop(['acousticness'], axis=1)\n",
    "validation_data = validation_data.drop(['instrumentalness'], axis=1)\n",
    "validation_data = validation_data.drop(['liveness'], axis=1)\n",
    "validation_data = validation_data.drop(['valence'], axis=1)\n",
    "validation_data = validation_data.drop(['duration_ms'], axis=1)\n",
    "validation_data = validation_data.drop(['time_signature'], axis=1)\n",
    "validation_data = np.asarray(validation_data,dtype=np.float64)\n",
    "validation_count = len(validation_data[:,0])\n",
    "print(validation_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training process\n",
    "\n",
    "for epoch in range(epoch_count):\n",
    "    for sample in range(training_count):\n",
    "        for node in range(H_dim):\n",
    "            preActivation_H[node] = np.dot(training_data[sample,:], weights_ItoH[:, node])\n",
    "            postActivation_H[node] = logistic(preActivation_H[node])\n",
    "            \n",
    "        FE = postActivation_O - target_output[sample]\n",
    "        \n",
    "        for H_node in range(H_dim):\n",
    "            S_error = FE * logistic_deriv(preActivation_O)\n",
    "            gradient_HtoO = S_error * postActivation_H[H_node]\n",
    "                       \n",
    "            for I_node in range(I_dim):\n",
    "                input_value = training_data[sample, I_node]\n",
    "                gradient_ItoH = S_error * weights_HtoO[H_node] * logistic_deriv(preActivation_H[H_node]) * input_value\n",
    "                \n",
    "                weights_ItoH[I_node, H_node] -= LR * gradient_ItoH\n",
    "                \n",
    "            weights_HtoO[H_node] -= LR * gradient_HtoO\n",
    "        preActivation_O = np.dot(postActivation_H, weights_HtoO)\n",
    "        postActivation_O = logistic(preActivation_O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original value: 39\n",
      "predicted score: 0.9991843645134685\n",
      "\n",
      "original value: 45\n",
      "predicted score: 0.9991843645134685\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#validation\n",
    "\n",
    "correct_classification_count = 0\n",
    "for sample in range(validation_count):\n",
    "    for node in range(H_dim):\n",
    "        preActivation_H[node] = np.dot(validation_data[sample,:], weights_ItoH[:, node])\n",
    "        postActivation_H[node] = logistic(preActivation_H[node])\n",
    "            \n",
    "    preActivation_O = np.dot(postActivation_H, weights_HtoO)\n",
    "    postActivation_O = logistic(preActivation_O)\n",
    "\n",
    "    print(\"original value: {}\".format(validation_output[sample]))\n",
    "    print(\"predicted score: {}\\n\".format(postActivation_O))\n",
    "#    if postActivation_O > 0.5:\n",
    "#        output = 1\n",
    "#    else:\n",
    "#        output = 0     \n",
    "#        \n",
    "#    if output == validation_output[sample]:\n",
    "#        correct_classification_count += 1\n",
    "\n",
    "#print('Percentage of correct classifications:')\n",
    "#print(correct_classification_count*100/validation_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
